{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6ISv94U4GtK"
   },
   "source": [
    "# Сентимент для твиттера\n",
    "\n",
    "[Данные](https://docs.google.com/file/d/0B04GJPshIjmPRnZManQwWEdTZjg/edit) [sentiment140](http://help.sentiment140.com/for-students) это англоязычный твиттер.\n",
    "\n",
    "Он уже поделен на train/test. Train часть была размечена автоматически -- по наличию определенных эмоджи в тексте.\n",
    "\n",
    "Тест часть была размечена людьми. Таким образом задача состоит в том, чтобы обучиться на шумных данных и сделать хорошие предсказания на тестовой выборке. И, конечно же, нужно превзойти бейзлайн решение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d5BmH4Cgvkvy"
   },
   "source": [
    "Запустите следующую ячейку, если работаете в google colab. Это поможет быстро загрузить данные в текущий runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116
    },
    "colab_type": "code",
    "id": "0pMOAJ12Jv3x",
    "outputId": "0ad86ee4-acb9-44d1-b6cf-21de5bb2fa29",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-10-09 19:17:12--  https://docs.google.com/uc?export=download&confirm=&id=0B04GJPshIjmPRnZManQwWEdTZjg\n",
      "Resolving docs.google.com... failed: Temporary failure in name resolution.\n",
      "wget: unable to resolve host address ‘docs.google.com’\n"
     ]
    }
   ],
   "source": [
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=0B04GJPshIjmPRnZManQwWEdTZjg' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=0B04GJPshIjmPRnZManQwWEdTZjg\" -O dataset.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nb_XPmNivso-"
   },
   "source": [
    "Для google colab: распаковка данных внутри runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99
    },
    "colab_type": "code",
    "id": "7kc-pJF6JxrP",
    "outputId": "4dc38c1a-708c-49bb-9491-7ed03ded96cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  dataset.zip\n",
      "  inflating: testdata.manual.2009.06.14.csv  \n",
      "  inflating: training.1600000.processed.noemoticon.csv  \n"
     ]
    }
   ],
   "source": [
    "!unzip dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EAiQbXe4v4I9"
   },
   "source": [
    "Загрузка предобученных эмбеддингов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "id": "o7skeI8PO2F7",
    "outputId": "e3c9c059-5140-4d7c-92fe-2e61ba6c6863"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-10-07 20:50:41--  http://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip\n",
      "Resolving nlp.stanford.edu... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip [following]\n",
      "--2018-10-07 20:50:41--  https://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip\n",
      "Connecting to nlp.stanford.edu|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1520408741 (1,4G) [application/zip]\n",
      "Saving to: ‘glove.twitter.27B.zip’\n",
      "\n",
      "glove.twitter.27B.z 100%[===================>]   1,42G  1,15MB/s    in 43m 55s \n",
      "\n",
      "2018-10-07 21:34:37 (564 KB/s) - ‘glove.twitter.27B.zip’ saved [1520408741/1520408741]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "colab_type": "code",
    "id": "Ktdn8hX8O5pV",
    "outputId": "a4a372e9-4914-41fb-bd5f-52de71e9bd71",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.twitter.27B.zip\n",
      "  inflating: glove.twitter.27B.100d.txt  \n",
      "  inflating: glove.twitter.27B.200d.txt  \n",
      "  inflating: glove.twitter.27B.25d.txt  \n",
      "  inflating: glove.twitter.27B.50d.txt  \n"
     ]
    }
   ],
   "source": [
    "!unzip glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "zUbgIfRG4GtM",
    "outputId": "988771c7-350c-4b30-8ca2-c7ac21091f12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gc\n",
    "\n",
    "np.random.seed(101)\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "mIRBlFny4GtS",
    "outputId": "f259ba09-74e0-4e72-b659-07e3d56698bf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>flag</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250977</th>\n",
       "      <td>0</td>\n",
       "      <td>1983354434</td>\n",
       "      <td>Sun May 31 12:59:58 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Yushimi</td>\n",
       "      <td>@Kardboard yea  ugh. I don't wanna move either...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150064</th>\n",
       "      <td>0</td>\n",
       "      <td>1883616871</td>\n",
       "      <td>Fri May 22 08:50:14 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>philwade</td>\n",
       "      <td>Guess there's a first time for everything, my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710275</th>\n",
       "      <td>0</td>\n",
       "      <td>2257860040</td>\n",
       "      <td>Sat Jun 20 15:00:38 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>JBnVFCLover786</td>\n",
       "      <td>My cousin is going to America and it's NOT FAI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367641</th>\n",
       "      <td>0</td>\n",
       "      <td>2049251254</td>\n",
       "      <td>Fri Jun 05 16:33:26 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ChelseyHart</td>\n",
       "      <td>@mitchelmusso Ahh this is my first comment to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575674</th>\n",
       "      <td>0</td>\n",
       "      <td>2211153017</td>\n",
       "      <td>Wed Jun 17 12:30:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>GGirl33</td>\n",
       "      <td>taking care of my good friend jessica she is s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment          id                          time      flag  \\\n",
       "250977          0  1983354434  Sun May 31 12:59:58 PDT 2009  NO_QUERY   \n",
       "150064          0  1883616871  Fri May 22 08:50:14 PDT 2009  NO_QUERY   \n",
       "710275          0  2257860040  Sat Jun 20 15:00:38 PDT 2009  NO_QUERY   \n",
       "367641          0  2049251254  Fri Jun 05 16:33:26 PDT 2009  NO_QUERY   \n",
       "575674          0  2211153017  Wed Jun 17 12:30:03 PDT 2009  NO_QUERY   \n",
       "\n",
       "              username                                               text  \n",
       "250977         Yushimi  @Kardboard yea  ugh. I don't wanna move either...  \n",
       "150064        philwade  Guess there's a first time for everything, my ...  \n",
       "710275  JBnVFCLover786  My cousin is going to America and it's NOT FAI...  \n",
       "367641     ChelseyHart  @mitchelmusso Ahh this is my first comment to ...  \n",
       "575674         GGirl33  taking care of my good friend jessica she is s...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./training.1600000.processed.noemoticon.csv\", header=None, encoding='latin-1', sep=',')\n",
    "train.columns = ['sentiment', 'id', 'time', 'flag', 'username', 'text']\n",
    "train = train.iloc[np.random.permutation(len(train))][:100000]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KgOJMbKS4GtW",
    "outputId": "64c4951a-615d-45d3-f987-15e0793a0c21",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "vkRO8t7h4Gta",
    "outputId": "685e24a7-b5de-4c56-f4b5-d8fb66ebed6f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>flag</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  id                          time     flag  username  \\\n",
       "0          4   3  Mon May 11 03:17:40 UTC 2009  kindle2    tpryan   \n",
       "1          4   4  Mon May 11 03:18:03 UTC 2009  kindle2    vcu451   \n",
       "2          4   5  Mon May 11 03:18:54 UTC 2009  kindle2    chadfu   \n",
       "3          4   6  Mon May 11 03:19:04 UTC 2009  kindle2     SIX15   \n",
       "4          4   7  Mon May 11 03:21:41 UTC 2009  kindle2  yamarama   \n",
       "\n",
       "                                                text  \n",
       "0  @stellargirl I loooooooovvvvvveee my Kindle2. ...  \n",
       "1  Reading my kindle2...  Love it... Lee childs i...  \n",
       "2  Ok, first assesment of the #kindle2 ...it fuck...  \n",
       "3  @kenburbary You'll love your Kindle2. I've had...  \n",
       "4  @mikefish  Fair enough. But i have the Kindle2...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"./testdata.manual.2009.06.14.csv\", encoding='latin-1', header=None)\n",
    "test.columns = ['sentiment', 'id', 'time', 'flag', 'username', 'text']\n",
    "test = test.drop(test[test.sentiment == 2].index)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EmwbihC_4Gtd",
    "outputId": "29a8ca69-4eb4-43f9-b521-ac445324ebcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sentiment.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CVWn-M-iwFoc"
   },
   "source": [
    "Предобработка твиттов очень важна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "raabazGy4Gth",
    "outputId": "673bdc97-9ce5-45f7-e951-cb5e5aa9f9fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/pavel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet, flags=re.MULTILINE)\n",
    "    tweet = re.sub(r'[_\"\\-;%()|.,+&=*%]', '', tweet)\n",
    "    tweet = re.sub(r'\\.', ' . ', tweet)\n",
    "    tweet = re.sub(r'\\!', ' !', tweet)\n",
    "    tweet = re.sub(r'\\?', ' ?', tweet)\n",
    "    tweet = re.sub(r'\\,', ' ,', tweet)\n",
    "    tweet = re.sub(r':', ' : ', tweet)\n",
    "    tweet = re.sub(r'#', ' # ', tweet)\n",
    "    #tweet = re.sub(r'@', ' @ ', tweet)\n",
    "    tweet = re.sub(r'd .c .', 'd.c.', tweet)\n",
    "    tweet = re.sub(r'u .s .', 'd.c.', tweet)\n",
    "    tweet = re.sub(r' amp ', ' and ', tweet)\n",
    "    tweet = re.sub(r'pm', ' pm ', tweet)\n",
    "    tweet = re.sub(r'news', ' news ', tweet)\n",
    "    tweet = re.sub(r' . . . ', ' ', tweet)\n",
    "    tweet = re.sub(r' .  .  . ', ' ', tweet)\n",
    "    tweet = re.sub(r' ! ! ', ' ! ', tweet)\n",
    "    tweet = re.sub(r'&amp', 'and', tweet)\n",
    "    return tweet\n",
    "\n",
    "def preprocess(text, remove_stopwords=True):\n",
    "    text = clean_tweet(text)\n",
    "    # Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "\n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        \n",
    "    msg = \" \".join(text)\n",
    "    \n",
    "    for t in text:\n",
    "        if t.startswith('http'):\n",
    "            msg = msg.replace(t, 'URL')\n",
    "        if t.startswith('@'):\n",
    "            msg = msg.replace(t, 'username')\n",
    "    \n",
    "    text = msg\n",
    "    \n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^a-z]\", \" \", text)\n",
    "    text = re.sub(r\"    \", \" \", text) # Remove any extra spaces\n",
    "    text = re.sub(r\"   \", \" \", text) # Remove any extra spaces\n",
    "    text = re.sub(r\"  \", \" \", text)\n",
    "    \n",
    "    # Return a list of words\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "lmgXVFcJ4Gtj",
    "outputId": "623fb857-6cb3-4151-aaa5-d6252547b3e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**BEFORE PREPROC:** @Kardboard yea  ugh. I don't wanna move either because all my textbooks and noted are all out on the table. Sigh.\n",
      "----\n",
      "**AFTER PREPROC:**  username yea ugh wanna move either textbooks noted table sigh\n"
     ]
    }
   ],
   "source": [
    "# Example of preprocessor work\n",
    "print('**BEFORE PREPROC:**', train['text'].values[0])\n",
    "print('-'*4)\n",
    "print('**AFTER PREPROC:** ', preprocess(train['text'].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "YUnabcxZ4Gtn",
    "outputId": "37db78f6-49c7-4c94-fbee-8789a3b14898"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250977</th>\n",
       "      <td>username yea ugh wanna move either textbooks n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150064</th>\n",
       "      <td>guess there s first time everything cars broke...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710275</th>\n",
       "      <td>cousin going america fair know wayyy pppl does...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367641</th>\n",
       "      <td>username ahh first comment youu love xxxand pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  sentiment\n",
       "250977  username yea ugh wanna move either textbooks n...          0\n",
       "150064  guess there s first time everything cars broke...          0\n",
       "710275  cousin going america fair know wayyy pppl does...          0\n",
       "367641  username ahh first comment youu love xxxand pl...          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[['text','sentiment']]\n",
    "train['text'] = list(map(preprocess, train['text']))\n",
    "train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "rCw447kl4Gtr",
    "outputId": "5cd7aacc-7066-4f04-fe03-503db12c92be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>flag</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>username loooooooovvvvvveee kindle dx cool fan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>reading kindle love lee childs good read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>ok first assesment kindle fucking rocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>username love kindle i ve mine months never lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  id                          time     flag username  \\\n",
       "0          4   3  Mon May 11 03:17:40 UTC 2009  kindle2   tpryan   \n",
       "1          4   4  Mon May 11 03:18:03 UTC 2009  kindle2   vcu451   \n",
       "2          4   5  Mon May 11 03:18:54 UTC 2009  kindle2   chadfu   \n",
       "3          4   6  Mon May 11 03:19:04 UTC 2009  kindle2    SIX15   \n",
       "\n",
       "                                                text  \n",
       "0  username loooooooovvvvvveee kindle dx cool fan...  \n",
       "1           reading kindle love lee childs good read  \n",
       "2           ok first assesment kindle fucking rocks   \n",
       "3  username love kindle i ve mine months never lo...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'] = list(map(preprocess, test['text']))\n",
    "test[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qj7d4iBUzk4A"
   },
   "outputs": [],
   "source": [
    "# Поменяем метки классов на более естественные:\n",
    "\n",
    "# 0:negative, 4:positive\n",
    "translate_labels = {0:0, 4:1} # 0:0 -- просто для наглядности:)\n",
    "train.sentiment = [translate_labels[t] for t in train.sentiment]\n",
    "test.sentiment = [translate_labels[t] for t in test.sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3fp9PMqfDtTz"
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"preprocessed_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sduh6xui4Gtu"
   },
   "source": [
    "# Бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "uWf8JtSc4Gtv"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "transformer = TfidfVectorizer(min_df=40, max_features=6000)\n",
    "X_train = transformer.fit_transform(train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vrRwW76R4Gtz"
   },
   "outputs": [],
   "source": [
    "X_test = transformer.transform(test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ohsaDHSs4Gt4"
   },
   "outputs": [],
   "source": [
    "y_train = train.sentiment\n",
    "y_test = test.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "9hBHt1dk4Gt7",
    "outputId": "9a914412-0a25-41d3-fa34-d7ada90a50cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8nbMFb5M4GuA"
   },
   "outputs": [],
   "source": [
    "# check on test part\n",
    "from sklearn.metrics import f1_score, roc_auc_score \n",
    "test_pred = lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "WblSPmoL0V9Y",
    "outputId": "262e0142-cc65-4f31-ece3-93c90148439d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04662516, 0.95337484],\n",
       "       [0.05971427, 0.94028573],\n",
       "       [0.18586407, 0.81413593],\n",
       "       [0.72101234, 0.27898766],\n",
       "       [0.51532991, 0.48467009]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O9__iSBB4GuN"
   },
   "source": [
    "**Для удобства возьмем в качестве метрики roc_auc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_TeAzsLE4GuO",
    "outputId": "932b091a-6b41-43f8-85c7-1c9af8e99a9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8664400571180232"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, test_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLCk8VQP4GuT"
   },
   "source": [
    "Это и есть то самое значение, которое необходимо превзойти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b7amP9O54GuU"
   },
   "source": [
    "# Tensorflow вступает в игру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndpHlAwQ4GuV",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "7j8JKLD85LYH",
    "outputId": "884af15d-604e-4f27-db9e-99bb2b3c0857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16444951542076309917\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JRn9kV_G4Gua"
   },
   "source": [
    "**Готовим датасет**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "y3Hk7flO4Gua"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(char_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zxA-912p4Gue"
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(train.text)\n",
    "vocab_size = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G1EDpcTpJmC5",
    "outputId": "801b493e-fd14-4e62-cbee-e800c77204ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61896"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UMqNgZm94Gug"
   },
   "outputs": [],
   "source": [
    "train_seqs = tokenizer.texts_to_sequences(train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "d_V8NgTU4Gui",
    "outputId": "672fadd6-19c1-4fee-8e52-818fc4a13d37"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFwczM8v8f4NJZfBEJ1VrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07a56cb128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(x) for x in train_seqs])\n",
    "plt.title(\"Распределение длин последовательностей\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "lAmhEmtP4Gum"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DD9LIm5d4Guo"
   },
   "outputs": [],
   "source": [
    "# обрезаем последовательности в начале, добиваем нулями до 20 при необходимости в конце\n",
    "# тут можно все поменять на свой вкус, конечно же\n",
    "padded = pad_sequences(train_seqs, maxlen=20, dtype='int32', padding='post', truncating='pre', value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5T2LBcsy4Guq",
    "outputId": "1ef2d5c9-1a5c-429a-b3da-eedb99b5928b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 20)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QRMZvpFIQ4aC"
   },
   "source": [
    "#### Загружаем эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7tfb6UozQ9vg"
   },
   "outputs": [],
   "source": [
    "#Load GLOVE vectors\n",
    "filepath_glove = 'glove.twitter.27B.100d.txt'\n",
    "glove_vocab = []\n",
    "glove_embd=[]\n",
    "embedding_dict = {}\n",
    " \n",
    "file = open(filepath_glove,'r',encoding='UTF-8')\n",
    "for line in file.readlines():\n",
    "    row = line.strip().split(' ')\n",
    "    vocab_word = row[0]\n",
    "    glove_vocab.append(vocab_word)\n",
    "    embed_vector = [float(i) for i in row[1:]] # convert to list of float\n",
    "    embedding_dict[vocab_word]=embed_vector\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6W0BOjk7SozR",
    "outputId": "423b5436-9abd-47f0-e5be-518e18ce15ff",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1193515"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XIHKH7EZTGot",
    "outputId": "ecbd03c5-5ca6-4035-80bb-5c68a61cf523"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61896"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wY45yY4e1By8"
   },
   "source": [
    "Подготовим матрицу для инициализации матрицы эмбеддингов модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "V_a92CfnRE8R"
   },
   "outputs": [],
   "source": [
    "# prepare embedding matrix\n",
    "num_words = vocab_size+1\n",
    "embedding_matrix = np.zeros((num_words, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embedding_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VVF7fQzCR_oX",
    "outputId": "00d2912b-c872-454b-9ee7-a673d257ffb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61897, 100)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "tKnSGyHDSPA5",
    "outputId": "1d7ac897-e2b2-4187-9b97-09290cadc561"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.5651e-02, -1.4665e-02, -2.0531e-01, -1.3928e-01, -4.5531e-01,\n",
       "        6.6880e-01, -1.5448e-01,  3.2308e-01, -5.1561e-01,  9.6171e-02,\n",
       "       -3.6832e-02,  2.7032e-01, -2.8622e+00,  4.1572e-01, -2.2041e-01,\n",
       "       -8.2353e-01, -7.0891e-01, -3.1757e-01, -7.4595e-01,  1.1605e+00,\n",
       "       -2.9937e-04, -1.3276e-02,  5.3844e-01,  3.2003e-01,  3.9048e-01,\n",
       "       -2.2494e+00, -6.9214e-01, -3.2294e-01,  6.8427e-01,  5.9943e-01,\n",
       "       -9.1371e-02, -5.6070e-01, -3.1685e-01, -1.1708e-01,  1.7076e+00,\n",
       "       -6.3555e-01, -4.3287e-01, -2.2535e-01,  3.5899e-01,  2.3817e-01,\n",
       "       -1.8517e+00,  3.0939e-01,  4.7932e-01, -8.7741e-01, -1.8584e-01,\n",
       "       -5.0600e-01,  2.8379e-02, -7.2791e-01,  8.4749e-02, -7.0856e-01,\n",
       "        3.5898e-01, -2.6869e-01,  1.2857e-01,  3.7286e-01,  3.6686e-01,\n",
       "       -2.9323e-01,  3.7081e-01, -6.0298e-01,  2.4040e-01, -5.0550e-01,\n",
       "       -2.8867e-01, -4.5598e-01,  7.7508e-02,  1.0154e-01,  2.9443e-01,\n",
       "        4.2504e-01, -2.3515e-01,  4.4486e-01, -1.5291e-01, -1.0447e-01,\n",
       "        2.9614e-01, -6.3704e-01,  3.1613e-01,  2.7299e-01, -6.2677e-01,\n",
       "        5.8366e-01, -7.3846e-01,  1.0140e+00, -7.8185e-02, -5.2589e-01,\n",
       "        1.4557e+00,  3.6629e-01,  3.7527e-01,  3.3924e-02, -1.3459e-01,\n",
       "        7.2309e-01, -7.9871e-01,  1.2158e-01,  2.5512e-01,  5.7559e-01,\n",
       "        5.3372e-01, -3.7430e-01, -2.1475e-01,  1.2555e-01,  7.2887e-01,\n",
       "       -5.7377e-01, -8.9212e-01, -3.1556e-01,  4.4199e-01, -4.0687e-01])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bm6o4yBo4Gux"
   },
   "source": [
    "**Теперь Tensorflow точно вступает в игру**\n",
    "\n",
    "Изготовим теперь удобный **tf.data.Dataset**\n",
    "\n",
    "Более подробно можно прочитать об этом [здесь](https://towardsdatascience.com/how-to-use-dataset-in-tensorflow-c758ef9e4428) и [здесь](https://www.tensorflow.org/performance/datasets_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6874"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xhx2FtZTDYw7"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "tH7wlrWRByp8"
   },
   "outputs": [],
   "source": [
    "emb_size = 100\n",
    "batch_size = tf.placeholder(tf.int64, shape=())  #made batch_size a placeholder\n",
    "learning_rate = 0.001\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "agmderJ4IbOM"
   },
   "outputs": [],
   "source": [
    "y_train = np.array(train.sentiment)\n",
    "y_train = np.expand_dims(y_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "PgwcdOcxNqus",
    "outputId": "111298e6-b62e-44ba-bccc-29f37f83477b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49989"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MY CODE\n",
    "np.count_nonzero(y_train == [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50011"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MY CODE\n",
    "np.count_nonzero(y_train == [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "eIvZj2y14Gux"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((padded, y_train)).shuffle(batch_size).repeat().batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MP1BpiohAZfV"
   },
   "source": [
    "С помощью dataset API можно удобно делать итератор для имеющихся данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xcPxVUjV4Guz",
    "outputId": "fa2b9b47-d096-49c5-b43c-84d67acd8452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'IteratorGetNext:0' shape=(?, 20) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(?, 1) dtype=int64>)\n"
     ]
    }
   ],
   "source": [
    "my_iterator = dataset.make_initializable_iterator() #Changed name iterator to my_iterator\n",
    "get_next = my_iterator.get_next()\n",
    "print(get_next)\n",
    "inputs, labels = get_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JgKjyHJJ7sdd"
   },
   "source": [
    "**Модель**\n",
    "\n",
    "Мы хотим сделать очень простую модель с однослойной LSTM ячейкой, которая будет пробегать по всей последовательности из слов длины 20. На каждом элементе последовательности LSTM выдает output. Мы хотим использовать output'ы для предсказания вероятности принадлежности последовательности к классу позитивных твиттов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T5Zzq2J51le2"
   },
   "source": [
    "Матрицу эмбеддингов фиксируем, она не будет тренироваться в процессе обучения модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Nl9jIipdJmDd"
   },
   "outputs": [],
   "source": [
    "embedding_mtx = tf.get_variable(name=\"embedding_mtx\",\n",
    "                                shape=embedding_matrix.shape,\n",
    "                                initializer=tf.constant_initializer(embedding_matrix),\n",
    "                                trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uXvsePQj1wAB"
   },
   "source": [
    "Эта функция позволяет по индексам элементов входной последовательности (`inputs`) составить матрицу из соответствующих векторов слов из матрицы эмбеддингов (`embedding_mtx`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "V0dp0CquB8_G"
   },
   "outputs": [],
   "source": [
    "inputs_embedded = tf.nn.embedding_lookup(params=embedding_mtx, ids=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J34nraUu2KrW"
   },
   "source": [
    "Посмотрим на размерность полученной матрицы: [размер батча, длина последовательности, размерность эмбеддинга]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mEIl4y4RCkhi",
    "outputId": "0cf3707b-fbb7-4396-9fd8-4ab5f33aa5b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup:0' shape=(?, 20, 100) dtype=float32>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of units is a parameter in the LSTM, referring to the dimensionality of the hidden state and dimensionality of the output state (they must be equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iPahVzMT4Gu1"
   },
   "outputs": [],
   "source": [
    "outputs, states = tf.nn.dynamic_rnn(cell=tf.nn.rnn_cell.LSTMCell(20), inputs=inputs_embedded, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputs -- это выходы LSTM после каждого элемента последовательности.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wO7SP7065vmK"
   },
   "outputs": [],
   "source": [
    "outputs = tf.layers.flatten(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "o0auPGwzFKcF"
   },
   "outputs": [],
   "source": [
    "logits = tf.layers.dense(inputs=outputs, units=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "n9w2mcHYAIIF",
    "outputId": "9cd5ff5c-aa2c-4240-d4bf-bb431d377372"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense/BiasAdd:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bC6EwGXpJmDr",
    "outputId": "49599ca0-a3f8-4c4d-d6f2-1cb02c777653"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sigmoid:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = tf.nn.sigmoid(logits)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WrNxRc6hFKaC"
   },
   "outputs": [],
   "source": [
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    labels=tf.cast(labels, dtype=tf.float32),\n",
    "    logits=logits,\n",
    "    name='loss'\n",
    ")\n",
    "loss = tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_iECRp-g4Gu4",
    "outputId": "1fa11e5e-3f31-472d-9933-37fc69a9c053"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "oT1X96sQ4Gu5"
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "qovQgvIYJEiX",
    "outputId": "36b030e8-6749-4ac6-8341-715d2411ff1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Loss:  0.002528295914332072\n",
      "Loss:  0.6123968171079953\n",
      "Loss:  0.5503690761327743\n",
      "Loss:  0.5417592176795005\n",
      "Loss:  0.5247061252593994\n",
      "Loss:  0.5142904767394065\n",
      "Loss:  0.5204855366051198\n",
      "Loss:  0.5005177731315295\n",
      "Loss:  0.5143412526448568\n",
      "Loss:  0.5211452835301558\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "num_epochs = 1\n",
    "num_iter_per_epoch = 3000\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(my_iterator.initializer, feed_dict={batch_size:10})\n",
    "\n",
    "for i in range(num_epochs):\n",
    "  print('Epoch ',i)\n",
    "  aver_loss = 0.\n",
    "  for j in range(num_iter_per_epoch):\n",
    "    #sess.run(my_iterator.initializer, feed_dict={batch_size:100})\n",
    "    loss_cur, _ = sess.run([loss, train_op])\n",
    "    aver_loss += loss_cur\n",
    "    if j % 300 == 0:\n",
    "      print('Loss: ', aver_loss / 300.)\n",
    "      aver_loss = 0.\n",
    "      \n",
    "    losses.append(loss_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "asaAQ2ITJU5m",
    "outputId": "c2aae4d0-0512-4a25-c40f-27fe07bad500",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f076c12a8d0>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f076c10db70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "71dyoLY-7ezf"
   },
   "source": [
    "**Измеряем точность**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ToINNWQtJmD4"
   },
   "outputs": [],
   "source": [
    "test_seqs = tokenizer.texts_to_sequences(test.text)\n",
    "padded_test = pad_sequences(test_seqs, maxlen=20, dtype='int32', padding='post', truncating='pre', value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GDnqhSws8ro3"
   },
   "outputs": [],
   "source": [
    "test_pred = sess.run(probs, feed_dict={inputs: padded_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rCtV-Pe0JmD8",
    "outputId": "109a6428-6d72-418e-c861-cec728d25fac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8931830880983423"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TWiv3S0Oc9Tb"
   },
   "source": [
    "** Мы улучшили результат TF-IDF модели, но кажется, что можно куда лучше**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUzok0OydIOz"
   },
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOquml5SQLsN"
   },
   "source": [
    "Исследуйте нейронку и опишите свои наблюдения. Зафиксируйте количество итераций обучения и меняйте параметры сети. \n",
    "Можно выбрать для исследования **любые 3 ** из предложенных вопросов.\n",
    "\n",
    "1.   Как размер батча влияет на roc_auc?\n",
    "2.   Как размерность скрытого слоя LSTM влияет на roc_auc?\n",
    "3.   Что изменится, если вместо всех outputs LSTM взять только последние выходы LSTM на последнем шаге. Улучшился или ухудшился при этом roc_auc?\n",
    "4.   Что изменится, если взять char эмбеддинги заместо word? Провести эксперименты, добится roc_auc > 0.5. (Это может оказаться сложным, потому можно взять одну эту задачку вместо 3х)\n",
    "5.   Что изменится, если взять несколько слоев LSTM?\n",
    "6.   Что изменится, если взять bidirectional LSTM?\n",
    "7.   Что если обучать эмбеддинги вместе с обучением модели и не использовать инициализацию предобученными эмбеддингами? Сколько потребуется итераций обучения, чтобы достичь результата с использованием предобученных эмбеддингов?\n",
    "\n",
    "Опишите подробно что вы делали словами и что у вас вышло.\n",
    "Код тоже нужно оставить доступным для обозрения.\n",
    "\n",
    "Получилось ли у вас улучшить результат нейронки?\n",
    "\n",
    "# Ваш отчет здесь\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем batch_size placeholder-ом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ToINNWQtJmD4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Loss:  0.002379842201868693\n",
      "Loss:  0.6299897193908691\n",
      "Loss:  0.5574150943756103\n",
      "Loss:  0.5408231464028358\n",
      "Loss:  0.5282930456101894\n",
      "Loss:  0.5125926007827123\n",
      "Loss:  0.5242535371581714\n",
      "Loss:  0.5018670225640138\n",
      "Loss:  0.513911392390728\n",
      "Loss:  0.5259201343854268\n",
      "10 - 0.8826597131681877\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.0022969716787338257\n",
      "Loss:  0.6060105899969737\n",
      "Loss:  0.5489293801784515\n",
      "Loss:  0.5303777330120405\n",
      "Loss:  0.5175716438889504\n",
      "Loss:  0.5183748721083006\n",
      "Loss:  0.5039493509133657\n",
      "Loss:  0.516900606850783\n",
      "Loss:  0.50747846459349\n",
      "Loss:  0.5026723119616509\n",
      "20 - 0.8926864096355622\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.0023463173707326253\n",
      "Loss:  0.6004307890931765\n",
      "Loss:  0.5286483051379521\n",
      "Loss:  0.5196998031934102\n",
      "Loss:  0.5024281308054924\n",
      "Loss:  0.518417315085729\n",
      "Loss:  0.5034371264775594\n",
      "Loss:  0.513405885497729\n",
      "Loss:  0.4948051498333613\n",
      "Loss:  0.5066860167185465\n",
      "30 - 0.8883715154901596\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.002276673913002014\n",
      "Loss:  0.608101854622364\n",
      "Loss:  0.5289291706681252\n",
      "Loss:  0.5152084278066953\n",
      "Loss:  0.5168128184477488\n",
      "Loss:  0.5123895620306332\n",
      "Loss:  0.5024231704076131\n",
      "Loss:  0.5078315687179565\n",
      "Loss:  0.502908142109712\n",
      "Loss:  0.49952995429436364\n",
      "40 - 0.8852051902899359\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.0023097811142603554\n",
      "Loss:  0.5872196551163992\n",
      "Loss:  0.5264720312754313\n",
      "Loss:  0.5173480238517125\n",
      "Loss:  0.5102449737985929\n",
      "Loss:  0.504739091595014\n",
      "Loss:  0.5065617656707764\n",
      "Loss:  0.5072087952494622\n",
      "Loss:  0.48801935394605\n",
      "Loss:  0.4841365800301234\n",
      "50 - 0.8927484944434096\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.0022821720441182454\n",
      "Loss:  0.5845563357075055\n",
      "Loss:  0.5199164289236069\n",
      "Loss:  0.5155319067835807\n",
      "Loss:  0.508626469373703\n",
      "Loss:  0.5079119890928269\n",
      "Loss:  0.5052519717812538\n",
      "Loss:  0.49113106697797776\n",
      "Loss:  0.4901916771133741\n",
      "Loss:  0.4944535979628563\n",
      "60 - 0.8846153846153845\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.0024325982729593914\n",
      "Loss:  0.5890903114279111\n",
      "Loss:  0.5243389359116555\n",
      "Loss:  0.5141895540555318\n",
      "Loss:  0.5049005910754204\n",
      "Loss:  0.5089739390214284\n",
      "Loss:  0.4919402321179708\n",
      "Loss:  0.4914716865619024\n",
      "Loss:  0.49365098536014557\n",
      "Loss:  0.48903301646312075\n",
      "70 - 0.8953250139690818\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.00234013835589091\n",
      "Loss:  0.5840578129887581\n",
      "Loss:  0.5225743068257968\n",
      "Loss:  0.51014489620924\n",
      "Loss:  0.5083210125565529\n",
      "Loss:  0.4957571483651797\n",
      "Loss:  0.4900118499000867\n",
      "Loss:  0.49169999251763025\n",
      "Loss:  0.4871289975444476\n",
      "Loss:  0.48514450192451475\n",
      "80 - 0.8920034767492394\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.002314285635948181\n",
      "Loss:  0.5746069417397182\n",
      "Loss:  0.5174844455718994\n",
      "Loss:  0.5109041801095009\n",
      "Loss:  0.5080609871943792\n",
      "Loss:  0.4887437156836192\n",
      "Loss:  0.4984233909845352\n",
      "Loss:  0.4886131610472997\n",
      "Loss:  0.4903647987047831\n",
      "Loss:  0.4820643722017606\n",
      "90 - 0.8950456323337679\n",
      "_________________\n"
     ]
    }
   ],
   "source": [
    "for k in range(10, 100, 10):\n",
    "    losses = []\n",
    "    num_epochs = 1\n",
    "    num_iter_per_epoch = 3000\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #sess.run(tf.initialize_all_variables())\n",
    "    #print(batch_size)\n",
    "    sess.run(my_iterator.initializer, feed_dict={batch_size:k})\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "      print('Epoch ',i)\n",
    "      aver_loss = 0.\n",
    "      for j in range(num_iter_per_epoch):\n",
    "        #sess.run(my_iterator.initializer, feed_dict={batch_size:100})\n",
    "        loss_cur, _ = sess.run([loss, train_op])\n",
    "        aver_loss += loss_cur\n",
    "        if j % 300 == 0:\n",
    "          print('Loss: ', aver_loss / 300.)\n",
    "          aver_loss = 0.\n",
    "      \n",
    "        losses.append(loss_cur)\n",
    "    \n",
    "    test_seqs = tokenizer.texts_to_sequences(test.text)\n",
    "    padded_test = pad_sequences(test_seqs, maxlen=20, dtype='int32', padding='post', truncating='pre', value=0.0)\n",
    "    test_pred = sess.run(probs, feed_dict={inputs: padded_test})\n",
    "    print(k, '-', roc_auc_score(y_test, test_pred))\n",
    "    print('_________________')\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GDnqhSws8ro3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Loss:  0.0023381205399831137\n",
      "Loss:  0.5437054060896238\n",
      "Loss:  0.5148271882534027\n",
      "Loss:  0.500658100148042\n",
      "Loss:  0.4932437040408452\n",
      "Loss:  0.4828136827548345\n",
      "Loss:  0.48222499946753183\n",
      "Loss:  0.47759351422389346\n",
      "Loss:  0.4666085907816887\n",
      "Loss:  0.4679609816273054\n",
      "100 - 0.8859191655801826\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.002298218806584676\n",
      "Loss:  0.5370235718290011\n",
      "Loss:  0.5026947150627772\n",
      "Loss:  0.48709537973006567\n",
      "Loss:  0.47706991036732993\n",
      "Loss:  0.47316710869471235\n",
      "Loss:  0.46318626751502356\n",
      "Loss:  0.45630533357461295\n",
      "Loss:  0.44934473037719724\n",
      "Loss:  0.44213198632001877\n",
      "200 - 0.8835289004780531\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.0023327364524205526\n",
      "Loss:  0.533442160487175\n",
      "Loss:  0.49513400355974835\n",
      "Loss:  0.4807643680771192\n",
      "Loss:  0.46990618884563445\n",
      "Loss:  0.460135114689668\n",
      "Loss:  0.4520846325159073\n",
      "Loss:  0.443179200788339\n",
      "Loss:  0.4331723301609357\n",
      "Loss:  0.42397677888472873\n",
      "300 - 0.868535419382877\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.002300527493158976\n",
      "Loss:  0.5261245142420133\n",
      "Loss:  0.4884942836562792\n",
      "Loss:  0.476628023982048\n",
      "Loss:  0.4632414519786835\n",
      "Loss:  0.4541697958111763\n",
      "Loss:  0.4427050409714381\n",
      "Loss:  0.43396009544531505\n",
      "Loss:  0.42453810761372246\n",
      "Loss:  0.4103805967171987\n",
      "400 - 0.8641894828335506\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.0023178311189015707\n",
      "Loss:  0.5234399691224099\n",
      "Loss:  0.4858000687758128\n",
      "Loss:  0.4661499125758807\n",
      "Loss:  0.4562068638205528\n",
      "Loss:  0.44142351021369297\n",
      "Loss:  0.43147490322589876\n",
      "Loss:  0.416619360546271\n",
      "Loss:  0.4047983427842458\n",
      "Loss:  0.38638300011555354\n",
      "500 - 0.8506549947227914\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.0023139089345932005\n",
      "Loss:  0.520264921983083\n",
      "Loss:  0.4799449066321055\n",
      "Loss:  0.46328197995821635\n",
      "Loss:  0.44997385770082476\n",
      "Loss:  0.43810907065868376\n",
      "Loss:  0.42443485726912816\n",
      "Loss:  0.4107018757859866\n",
      "Loss:  0.39510398189226786\n",
      "Loss:  0.3787075591087341\n",
      "600 - 0.8262556652387161\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.0023220827182133994\n",
      "Loss:  0.5185314560929934\n",
      "Loss:  0.4765500562389692\n",
      "Loss:  0.459411280353864\n",
      "Loss:  0.4459376307328542\n",
      "Loss:  0.43252630054950714\n",
      "Loss:  0.41756316274404526\n",
      "Loss:  0.40120698034763336\n",
      "Loss:  0.3839110730091731\n",
      "Loss:  0.36536485979954403\n",
      "700 - 0.8596883342646056\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.002410682241121928\n",
      "Loss:  0.5178771781921386\n",
      "Loss:  0.4743286367257436\n",
      "Loss:  0.4547530736525853\n",
      "Loss:  0.4388868103424708\n",
      "Loss:  0.42179738730192184\n",
      "Loss:  0.40385762830575306\n",
      "Loss:  0.3853862574696541\n",
      "Loss:  0.365365968644619\n",
      "Loss:  0.3464445122083028\n",
      "800 - 0.803129074315515\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.0023221127192179364\n",
      "Loss:  0.5150405583779017\n",
      "Loss:  0.47206592609484993\n",
      "Loss:  0.45306597342093785\n",
      "Loss:  0.4356461868683497\n",
      "Loss:  0.41866478373607\n",
      "Loss:  0.3997132209936778\n",
      "Loss:  0.38004460086425146\n",
      "Loss:  0.3579594521721204\n",
      "Loss:  0.3375433019797007\n",
      "900 - 0.8153287390575527\n",
      "_________________\n",
      "Epoch  0\n",
      "Loss:  0.002313212553660075\n",
      "Loss:  0.5143935014804204\n",
      "Loss:  0.47063031554222107\n",
      "Loss:  0.4501694828271866\n",
      "Loss:  0.43320491979519526\n",
      "Loss:  0.41621185968319574\n",
      "Loss:  0.39791877796252567\n",
      "Loss:  0.3755723848938942\n",
      "Loss:  0.3530209400256475\n",
      "Loss:  0.3316723157962163\n",
      "1000 - 0.8183708946420811\n",
      "_________________\n"
     ]
    }
   ],
   "source": [
    "for k in range(100, 1001, 100):\n",
    "    losses = []\n",
    "    num_epochs = 1\n",
    "    num_iter_per_epoch = 3000\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #sess.run(tf.initialize_all_variables())\n",
    "    #print(batch_size)\n",
    "    sess.run(my_iterator.initializer, feed_dict={batch_size:k})\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "      print('Epoch ',i)\n",
    "      aver_loss = 0.\n",
    "      for j in range(num_iter_per_epoch):\n",
    "        #sess.run(my_iterator.initializer, feed_dict={batch_size:100})\n",
    "        loss_cur, _ = sess.run([loss, train_op])\n",
    "        aver_loss += loss_cur\n",
    "        if j % 300 == 0:\n",
    "          print('Loss: ', aver_loss / 300.)\n",
    "          aver_loss = 0.\n",
    "      \n",
    "        losses.append(loss_cur)\n",
    "    \n",
    "    test_seqs = tokenizer.texts_to_sequences(test.text)\n",
    "    padded_test = pad_sequences(test_seqs, maxlen=20, dtype='int32', padding='post', truncating='pre', value=0.0)\n",
    "    test_pred = sess.run(probs, feed_dict={inputs: padded_test})\n",
    "    print(k, '-', roc_auc_score(y_test, test_pred))\n",
    "    print('_________________')\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, оптимальный результат получается при значении batch_size 70-90, далее результаты нейронки начинают ухудшатся"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n"
     ]
    }
   ],
   "source": [
    "hidden = [10*i for i in range(1,10)] + [100*i for i in range(1, 11)]\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Loss:  0.0022925553719202675\n",
      "Loss:  0.6274890024463335\n",
      "Loss:  0.557229950328668\n",
      "Loss:  0.5501462929447491\n",
      "Loss:  0.5291825472315153\n",
      "Loss:  0.5181784090399743\n",
      "Loss:  0.5235713150600593\n",
      "Loss:  0.5048134921491146\n",
      "Loss:  0.519852185746034\n",
      "Loss:  0.5276661651333173\n",
      "10 - 0.8799279816228969\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.0023632081349690757\n",
      "Loss:  0.618679030785958\n",
      "Loss:  0.5472161042193572\n",
      "Loss:  0.5404152484734853\n",
      "Loss:  0.5297248768309752\n",
      "Loss:  0.5112544097503027\n",
      "Loss:  0.521993125975132\n",
      "Loss:  0.49946389416853587\n",
      "Loss:  0.5174602750440439\n",
      "Loss:  0.5229433760543665\n",
      "20 - 0.8871919041410568\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.0025938745339711506\n",
      "Loss:  0.603918529599905\n",
      "Loss:  0.544056781232357\n",
      "Loss:  0.5391336629291376\n",
      "Loss:  0.5275281204283238\n",
      "Loss:  0.5132931179801623\n",
      "Loss:  0.5225823112825553\n",
      "Loss:  0.5015843677520752\n",
      "Loss:  0.5161158482730389\n",
      "Loss:  0.5256319081783295\n",
      "30 - 0.8917240951139256\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.002439977725346883\n",
      "Loss:  0.603698807110389\n",
      "Loss:  0.5455869468053182\n",
      "Loss:  0.5368146307269732\n",
      "Loss:  0.5299078675111135\n",
      "Loss:  0.5101837304234504\n",
      "Loss:  0.5235892679790656\n",
      "Loss:  0.5016372721890608\n",
      "Loss:  0.5156788456439972\n",
      "Loss:  0.5244816361367702\n",
      "40 - 0.8899546780902713\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.002313013474146525\n",
      "Loss:  0.59392310688893\n",
      "Loss:  0.5435955242315929\n",
      "Loss:  0.5348300677041212\n",
      "Loss:  0.5292431131501992\n",
      "Loss:  0.5110847565035025\n",
      "Loss:  0.520785202930371\n",
      "Loss:  0.5004953708748022\n",
      "Loss:  0.5161543850600719\n",
      "Loss:  0.522229593048493\n",
      "50 - 0.8899857204941951\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.002385094364484151\n",
      "Loss:  0.5934772385160129\n",
      "Loss:  0.5431388783454895\n",
      "Loss:  0.5380851113299528\n",
      "Loss:  0.5263133765260378\n",
      "Loss:  0.5116687811414401\n",
      "Loss:  0.5199319482843081\n",
      "Loss:  0.4980938423673312\n",
      "Loss:  0.5141007819275061\n",
      "Loss:  0.5256488277514776\n",
      "60 - 0.8888371515490159\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.002426707943280538\n",
      "Loss:  0.596098706026872\n",
      "Loss:  0.5449348604182402\n",
      "Loss:  0.5370543573300044\n",
      "Loss:  0.5289382227758567\n",
      "Loss:  0.5129967606564363\n",
      "Loss:  0.5203575763106346\n",
      "Loss:  0.49919536054134367\n",
      "Loss:  0.5165098218123118\n",
      "Loss:  0.5221273463964462\n",
      "70 - 0.8900167628981188\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.002232718070348104\n",
      "Loss:  0.6009192976355553\n",
      "Loss:  0.5471713992953301\n",
      "Loss:  0.5395349657038847\n",
      "Loss:  0.5296315607925256\n",
      "Loss:  0.5147254632413387\n",
      "Loss:  0.52407858222723\n",
      "Loss:  0.503992396046718\n",
      "Loss:  0.5160889306664467\n",
      "Loss:  0.5255103401839734\n",
      "80 - 0.8921276463649345\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.0022921208540598553\n",
      "Loss:  0.5906055371463299\n",
      "Loss:  0.5468452667196592\n",
      "Loss:  0.5411866510907809\n",
      "Loss:  0.5282244267563025\n",
      "Loss:  0.5139500112334887\n",
      "Loss:  0.5226891898115475\n",
      "Loss:  0.5026347631216049\n",
      "Loss:  0.5152673201262951\n",
      "Loss:  0.5234032692511876\n",
      "90 - 0.8913515862668405\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.002135095198949178\n",
      "Loss:  0.5923142395913601\n",
      "Loss:  0.5470806356271108\n",
      "Loss:  0.5409316135694583\n",
      "Loss:  0.5305860478182634\n",
      "Loss:  0.5145265604058902\n",
      "Loss:  0.5221928185721239\n",
      "Loss:  0.5035013675192992\n",
      "Loss:  0.5166954373319944\n",
      "Loss:  0.5271296763916811\n",
      "100 - 0.8859812503880302\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.002361749609311422\n",
      "Loss:  0.5939083163936932\n",
      "Loss:  0.5507261007030805\n",
      "Loss:  0.5420528108874957\n",
      "Loss:  0.5312868078549703\n",
      "Loss:  0.517863607207934\n",
      "Loss:  0.5247776820758978\n",
      "Loss:  0.5045275494704644\n",
      "Loss:  0.51826568638285\n",
      "Loss:  0.5285647298892339\n",
      "200 - 0.8874092009685229\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.0021818256378173828\n",
      "Loss:  0.6019768658777078\n",
      "Loss:  0.5534969726701577\n",
      "Loss:  0.5431452472507954\n",
      "Loss:  0.5350336320201556\n",
      "Loss:  0.517602787911892\n",
      "Loss:  0.5260901254415512\n",
      "Loss:  0.5042743279536566\n",
      "Loss:  0.5180094266682863\n",
      "Loss:  0.5284796584645907\n",
      "300 - 0.8830943068231203\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.0023300747076670327\n",
      "Loss:  0.5990140586098035\n",
      "Loss:  0.5545914843678474\n",
      "Loss:  0.5493408606449763\n",
      "Loss:  0.5370881924033165\n",
      "Loss:  0.5194690265754859\n",
      "Loss:  0.524658770908912\n",
      "Loss:  0.5066633184750875\n",
      "Loss:  0.5185894385973613\n",
      "Loss:  0.5275282645225525\n",
      "400 - 0.8836841124976719\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.0023788400491078694\n",
      "Loss:  0.5984376723567645\n",
      "Loss:  0.5561081779872378\n",
      "Loss:  0.5463168046871821\n",
      "Loss:  0.5365755426386992\n",
      "Loss:  0.5212472320099671\n",
      "Loss:  0.5271806970735391\n",
      "Loss:  0.5072343918681145\n",
      "Loss:  0.5201228949427604\n",
      "Loss:  0.5300614491601785\n",
      "500 - 0.8852051902899362\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.002246949474016825\n",
      "Loss:  0.6036439521114031\n",
      "Loss:  0.557119273096323\n",
      "Loss:  0.5509786358475686\n",
      "Loss:  0.540189282099406\n",
      "Loss:  0.5242838124434154\n",
      "Loss:  0.5277476832270622\n",
      "Loss:  0.5086927375694116\n",
      "Loss:  0.5228109553456306\n",
      "Loss:  0.5275325953463713\n",
      "600 - 0.881976780281865\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.0022464515765508015\n",
      "Loss:  0.603187884191672\n",
      "Loss:  0.560307790885369\n",
      "Loss:  0.5503430153429508\n",
      "Loss:  0.5386357540885608\n",
      "Loss:  0.5250216549138228\n",
      "Loss:  0.530552750180165\n",
      "Loss:  0.5077783768375714\n",
      "Loss:  0.5223199030260245\n",
      "Loss:  0.5283966422080993\n",
      "700 - 0.8812938473955424\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.0023106137911478677\n",
      "Loss:  0.612655539015929\n",
      "Loss:  0.559978523850441\n",
      "Loss:  0.5537147445976734\n",
      "Loss:  0.5424478916327159\n",
      "Loss:  0.5239962127059699\n",
      "Loss:  0.5310871996978919\n",
      "Loss:  0.5104388909538587\n",
      "Loss:  0.5250776806473731\n",
      "Loss:  0.5298693748315175\n",
      "800 - 0.8819457378779413\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.002246521512667338\n",
      "Loss:  0.6079122905433177\n",
      "Loss:  0.5597401784857114\n",
      "Loss:  0.5560917226473491\n",
      "Loss:  0.5436283401648203\n",
      "Loss:  0.5265725463628769\n",
      "Loss:  0.5320745787024498\n",
      "Loss:  0.5111598188678423\n",
      "Loss:  0.5236838972568512\n",
      "Loss:  0.5307894567151864\n",
      "900 - 0.8765754019991309\n",
      "_______________\n",
      "Epoch  0\n",
      "Loss:  0.0025371170043945314\n",
      "Loss:  0.6128459111849467\n",
      "Loss:  0.5635687824587027\n",
      "Loss:  0.5553575668732326\n",
      "Loss:  0.5449060185750325\n",
      "Loss:  0.5238248666624228\n",
      "Loss:  0.533488483975331\n",
      "Loss:  0.510487151145935\n",
      "Loss:  0.5258309350411097\n",
      "Loss:  0.532121930718422\n",
      "1000 - 0.8761097659402745\n",
      "_______________\n"
     ]
    }
   ],
   "source": [
    "for hidden_size in hidden:\n",
    "    tf.reset_default_graph()\n",
    "    batch_size = tf.placeholder(tf.int64, shape=()) \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((padded, y_train)).shuffle(batch_size).repeat().batch(batch_size)\n",
    "    my_iterator = dataset.make_initializable_iterator() #Changed name iterator to my_iterator\n",
    "    get_next = my_iterator.get_next()\n",
    "    inputs, labels = get_next\n",
    "    embedding_mtx = tf.get_variable(name=\"embedding_mtx\",\n",
    "                                shape=embedding_matrix.shape,\n",
    "                                initializer=tf.constant_initializer(embedding_matrix),\n",
    "                                trainable=False)\n",
    "    \n",
    "    \n",
    "    inputs_embedded = tf.nn.embedding_lookup(params=embedding_mtx, ids=inputs)\n",
    "    \n",
    "    lstm_cell = tf.nn.rnn_cell.LSTMCell(hidden_size)    \n",
    "    outputs, states = tf.nn.dynamic_rnn(cell=lstm_cell, inputs=inputs_embedded, dtype=tf.float32)\n",
    "    outputs = tf.layers.flatten(outputs)\n",
    "    logits = tf.layers.dense(inputs=outputs, units=1)\n",
    "    probs = tf.nn.sigmoid(logits)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    labels=tf.cast(labels, dtype=tf.float32),\n",
    "    logits=logits,\n",
    "    name='loss')\n",
    "    loss = tf.reduce_mean(loss)\n",
    "\n",
    "    losses = []\n",
    "    num_epochs = 1\n",
    "    num_iter_per_epoch = 3000\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(my_iterator.initializer, feed_dict={batch_size:10})\n",
    "    \n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "      print('Epoch ',i)\n",
    "      aver_loss = 0.\n",
    "      for j in range(num_iter_per_epoch):\n",
    "        #sess.run(my_iterator.initializer, feed_dict={batch_size:100})\n",
    "        loss_cur, _ = sess.run([loss, train_op])\n",
    "        aver_loss += loss_cur\n",
    "        if j % 300 == 0:\n",
    "          print('Loss: ', aver_loss / 300.)\n",
    "          aver_loss = 0.\n",
    "      \n",
    "        losses.append(loss_cur)\n",
    "    \n",
    "    test_seqs = tokenizer.texts_to_sequences(test.text)\n",
    "    padded_test = pad_sequences(test_seqs, maxlen=20, dtype='int32', padding='post', truncating='pre', value=0.0)\n",
    "    test_pred = sess.run(probs, feed_dict={inputs: padded_test})\n",
    "    print(hidden_size, '-', roc_auc_score(y_test, test_pred))\n",
    "    print('_______________')\n",
    "    gc.collect()\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, размерность скрытого слоя практически не влият на roc_auc"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "hw3_rnn_final.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
