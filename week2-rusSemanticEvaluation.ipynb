{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача\n",
    "\n",
    "Задача, которую вам предстоит решать, была поставлена на [соревновании](https://russe.nlpub.org/2018/wsi/) в рамках конференции Dialog-2018.\n",
    "\n",
    "---\n",
    "\n",
    "### Краткое описание\n",
    "\n",
    "Ваша задача разработать систему, способную разрешать неоднозначность, возникающую в употреблении омонимичных форм.\n",
    "\n",
    "### Развернутое описание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>word</th>\n",
       "      <th>gold_sense_id</th>\n",
       "      <th>predict_sense_id</th>\n",
       "      <th>positions</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>замок владимира мономаха в любече . многочисле...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>шильонский замок замок шильйон ( ) , известный...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>проведения архитектурно - археологических рабо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>топи с . , л . белокуров легенда о завещании м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>великий князь литовский гедимин после успешной...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  context_id   word  gold_sense_id  predict_sense_id  positions  \\\n",
       "0          1  замок              1               NaN        NaN   \n",
       "1          2  замок              1               NaN        NaN   \n",
       "2          3  замок              1               NaN        NaN   \n",
       "3          4  замок              1               NaN        NaN   \n",
       "4          5  замок              1               NaN        NaN   \n",
       "\n",
       "                                             context  \n",
       "0  замок владимира мономаха в любече . многочисле...  \n",
       "1  шильонский замок замок шильйон ( ) , известный...  \n",
       "2  проведения архитектурно - археологических рабо...  \n",
       "3  топи с . , л . белокуров легенда о завещании м...  \n",
       "4  великий князь литовский гедимин после успешной...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/pavel/MyDocs/Machine Learning/Tinkoff/lecture2/train.csv\", sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", уже в стародавние времена действовала переправа через реку , а укрепление пруссов на твангсте так и напрашивалось на закладку орденской крепости . замок был выстроен из дерева на месте прусского городища тувангсте и на протяжении всего xiii века неоднократно подвергался нападениям восставших пруссов и литовских отрядов . замок был основан в январе года как деревянное строение , двумя годами позже началось возведение кирпичного замка . замок служил резиденцией маршалов тевтонского ордена и был центром сбора рыцарских походов в великое княжество литовское в xiv веке . с\n"
     ]
    }
   ],
   "source": [
    "print(data.loc[30, 'context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "замок владимира мономаха в любече . многочисленные укрепленные монастыри также не являлись замками как таковыми — это были крепости . ранние европейские замки строились преимущественно из дерева они опоясывались деревянной оградой — палисадом уже тогда вокруг замков стали появляться рвы . примером такого замка может служить вышгородский замок киевских князей . каменное замковое строительство распространилось в западной и центральной европе лишь к xii веку . главной частью средневекового замка являлась центральная башня — донжон , выполнявшая функции цитадели . помимо своих оборонительных функций , донжон являлся непосредственным жилищем феодала . также в главной башне\n"
     ]
    }
   ],
   "source": [
    "k = data['context'].tolist()\n",
    "print(k[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам дается набор \"главных слов\". Или слов, которые имеют несколько возможных смыслов в тексте.\n",
    "\n",
    "Например, слово `лук` может встречаться в значении `оружие` или в значении `овощ`.\n",
    "\n",
    "Ваша задача сопоставить одинаковые метки тем контекстам, в которых \"главное слово\" встречается в одном и том же значении.\n",
    "Важно учесть, что предполагается, что число возможных смыслов у \"главного слова\" заранее неизвестно. Таким образом это фактически задача кластеризации с заранее неизвестным числом классов.\n",
    "\n",
    "Также предполагается, что система будет применяться к \"главным словам\", которых нет в вашей обучающей выборке.\n",
    "\n",
    "В текущем варианте задания ваша задача построить и протестировать систему на датасете `wiki-wiki`, собранном из статей википедии.\n",
    "\n",
    "Это очень маленький датасет, в нем всего 4 \"главных слова\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['замок', 'лук', 'суда', 'бор'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.word.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. это тренировочный датасет, правильные метки для каждого контекста известны и можно посмотреть некоторую статистику по ним.\n",
    "\n",
    "**Сколько контекстов приходится на каждое слово?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word\n",
       "замок    138\n",
       "суда     135\n",
       "лук      110\n",
       "бор       56\n",
       "Name: context, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:,['word', 'gold_sense_id', 'context']]\\\n",
    ".groupby(['word']).count()['context'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cколько контекстов приходится на одно смысловое значение слова?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word   gold_sense_id\n",
       "бор    1                 14\n",
       "       2                 42\n",
       "замок  1                100\n",
       "       2                 38\n",
       "лук    1                 65\n",
       "       2                 45\n",
       "суда   1                100\n",
       "       2                 35\n",
       "Name: context, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:,['word', 'gold_sense_id', 'context']]\\\n",
    ".groupby(['word', 'gold_sense_id'])['context'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word   gold_sense_id\n",
       "бор    1                 14\n",
       "       2                 42\n",
       "замок  1                100\n",
       "       2                 38\n",
       "лук    1                 65\n",
       "       2                 45\n",
       "суда   1                100\n",
       "       2                 35\n",
       "Name: context, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:,['word', 'gold_sense_id', 'context']]\\\n",
    ".groupby(['word', 'gold_sense_id'])['context'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важное замечание**\n",
    "\n",
    "Как можно заметить, в этом датасете ровно по 2 смысла у каждого слова.\n",
    "\n",
    "Таким образом, разрешается в качестве `k` у `KMeans` взять значение 2.\n",
    "\n",
    "```python\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "KMeans(\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Про кластеризацию**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# запускаем кластеризацию отдельно для каждого набора контекстов, соответствующих своему \"главному слову\"\n",
    "km = KMeans(n_clusters=2)\n",
    "# Таким образом запускаем\n",
    "# km.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Что нужно сделать, чтобы посчитать метрику ARI?**\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "```\n",
    "Передать туда предсказанные метки и `gold_sense_id` из датасета.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "**План**\n",
    "1. Ознакомится с постановкой задачи и метрикой [ARI](https://en.wikipedia.org/wiki/Rand_index#Adjusted_Rand_index)\n",
    "2. Получить вектора-представления слов. Возможные пути решения:\n",
    "    - Обучить эмбеддинги с помощью [FastText](https://github.com/facebookresearch/fastText) на найденном вами же большом корпусе русского языка. \n",
    "    - Скачать готовые эмбеддинги. Это потребует определенного препроцессинга тестового датасета, чтобы слова в нем соответствовали словам в словаре скачанных эмбеддингов (например, в случае использования [rusVectores](http://rusvectores.org/ru/models/) потребуется добавить к каждому слову часть речи).\n",
    "3. Придумать способ представления контекста с помощью имеющихся эмбеддингов слов. Hint: можно также воспользоваться знаниями о TF-IDF представлении текста в совокупности с предобученными эмбеддингами слов.\n",
    "4. Воспользоваться алгоритмом кластеризации KMeans чтобы собрать контексты с одинаковым смысловым значением \"главного слова\" в один кластер. \n",
    "5. Посчитать метрику ARI для полученной кластеризации.\n",
    "\n",
    "Лучшее представление текста дает лучшую кластеризацию. Фокус данного задания не на алгоритме кластеризации, а на получении наиболее хорошего представления для векторов контекста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Для удобства работы с эмбеддингами предлагается воспользоваться пакетом `gensim`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGroups = []\n",
    "for word in data.word.unique():\n",
    "    dataGroups.append(data.loc[data['word'] == word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from future import standard_library\n",
    "import sys\n",
    "import os\n",
    "import wget\n",
    "from ufal.udpipe import Model, Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag_ud(pipeline, text='Текст нужно передать функции в виде строки!', pos=True):\n",
    "    # если частеречные тэги не нужны (например, их нет в модели), выставьте pos=False\n",
    "    # в этом случае на выход будут поданы только леммы\n",
    "\n",
    "    # обрабатываем текст, получаем результат в формате conllu:\n",
    "    processed = pipeline.process(text)\n",
    "\n",
    "    # пропускаем строки со служебной информацией:\n",
    "    content = [l for l in processed.split('\\n') if not l.startswith('#')]\n",
    "\n",
    "    # извлекаем из обработанного текста лемму и тэг\n",
    "    tagged = [w.split('\\t')[2].lower() + '_' + w.split('\\t')[3] for w in content if w]\n",
    "\n",
    "    tagged_propn = []\n",
    "    propn = []\n",
    "    for t in tagged:\n",
    "        if t.endswith('PROPN'):\n",
    "            if propn:\n",
    "                propn.append(t)\n",
    "            else:\n",
    "                propn = [t]\n",
    "        elif t.endswith('PUNCT'):\n",
    "            propn = []\n",
    "            continue  # я здесь пропускаю знаки препинания, но вы можете поступить по-другому\n",
    "        else:\n",
    "            if len(propn) > 1:\n",
    "                name = '::'.join([x.split('_')[0] for x in propn]) + '_PROPN'\n",
    "                tagged_propn.append(name)\n",
    "            elif len(propn) == 1:\n",
    "                tagged_propn.append(propn[0])\n",
    "            tagged_propn.append(t)\n",
    "            propn = []\n",
    "    if not pos:\n",
    "        tagged_propn = [t.split('_')[0] for t in tagged_propn]\n",
    "    return tagged_propn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embaddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "wordVec = KeyedVectors.load_word2vec_format(\"/home/pavel/MyDocs/Machine Learning/Tinkoff/lecture2/ruscorpora_upos_skipgram_300_5_2018.vec\", binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First approach - Average of Word2Vec vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model.load('udpipe_syntagrus.model')\n",
    "pipeline = Pipeline(model, 'tokenize', Pipeline.DEFAULT, Pipeline.DEFAULT, 'conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_vector_average(data, wordVec):\n",
    "    textVec= []\n",
    "    first = int(data['context_id'].tolist()[0]) - 1\n",
    "    for i in range(data.shape[0]):\n",
    "        words = tag_ud(pipeline, data.loc[first + i, 'context'])\n",
    "        vectors = []\n",
    "        for word in words:\n",
    "            if word in wordVec:\n",
    "                vectors.append(wordVec[word])\n",
    "        textVec.append(np.average(vectors, axis=0)) \n",
    "    return textVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "def predict_precesion_avr(num, dataGroups, wordVec):\n",
    "    textVec = text_vector_average(dataGroups[num], wordVec)\n",
    "    km = KMeans(n_clusters=2)\n",
    "    pred_sense = km.fit_predict(textVec)\n",
    "    gold_sense = dataGroups[num]['gold_sense_id'].values\n",
    "    res = adjusted_rand_score(pred_sense, gold_sense)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22418165790824132\n"
     ]
    }
   ],
   "source": [
    "res1 = predict_precesion_avr(0, dataGroups, wordVec)\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9279187206925574\n"
     ]
    }
   ],
   "source": [
    "res2 = predict_precesion_avr(1, dataGroups, wordVec)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32101725080207605\n"
     ]
    }
   ],
   "source": [
    "res3 = predict_precesion_avr(2, dataGroups, wordVec)\n",
    "print(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "res4 = predict_precesion_avr(3, dataGroups, wordVec)\n",
    "print(res4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Среднее значение ARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6182794073507187\n"
     ]
    }
   ],
   "source": [
    "print((res1 + res2 + res3 + res4)/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second approach - Average of Word2Vec vectors with TF-IDF without vectors normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_idf_avrg_unnorm(contexts, words, vectors, textNum):\n",
    "    newVectors = []\n",
    "    for i in range(len(words)):\n",
    "        word = words[i]\n",
    "        vec = vectors[i]\n",
    "        tfIdfScore = tfidf(word, contexts[textNum], contexts)\n",
    "        newVectors.append(tfIdfScore*vec)\n",
    "    return np.average(newVectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_vector_tfidf_unnorm(contexts, data, wordVec):\n",
    "    textVec= []\n",
    "    first = int(data['context_id'].tolist()[0]) - 1\n",
    "    for i in range(data.shape[0]):\n",
    "        #print(\"Text\", i, \"is OK\")\n",
    "        words = contexts[i].split()\n",
    "        vectors = []\n",
    "        validWords = []\n",
    "        for word in words:\n",
    "            if word in wordVec:\n",
    "                vectors.append(wordVec[word])\n",
    "                validWords.append(word)\n",
    "        textVec.append(tf_idf_avrg_unnorm(contexts, validWords, vectors, i)) \n",
    "    return textVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_contexts(n):\n",
    "    contexts = []\n",
    "    first = int(dataGroups[n]['context_id'].tolist()[0]) - 1\n",
    "    for i in range(dataGroups[n].shape[0]):\n",
    "        text = ' '.join(tag_ud(pipeline, dataGroups[n].loc[first + i, 'context']))\n",
    "        contexts.append(tb(text))\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_precesion_tfidf_unnorm(num, dataGroups, wordVec):\n",
    "    contexts = set_contexts(num)\n",
    "    textVec = text_vector_tfidf_unnorm(contexts, dataGroups[num], wordVec)\n",
    "    km = KMeans(n_clusters=2)\n",
    "    pred_sense = km.fit_predict(textVec)\n",
    "    gold_sense = dataGroups[num]['gold_sense_id'].values\n",
    "    res = adjusted_rand_score(pred_sense, gold_sense)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02348013466993366\n"
     ]
    }
   ],
   "source": [
    "res1 = predict_precesion_tfidf_unnorm(0, dataGroups, wordVec)\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08547435755153875\n"
     ]
    }
   ],
   "source": [
    "res2 = predict_precesion_tfidf_unnorm(1, dataGroups, wordVec)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4247564197996499\n"
     ]
    }
   ],
   "source": [
    "res3 = predict_precesion_tfidf_unnorm(2, dataGroups, wordVec)\n",
    "print(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051325199831720625\n"
     ]
    }
   ],
   "source": [
    "res4 = predict_precesion_tfidf_unnorm(3, dataGroups, wordVec)\n",
    "print(res4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Среднее значение ARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14625902796321072\n"
     ]
    }
   ],
   "source": [
    "print((res1+res2+res3+res4)/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Third approach - Average of Word2Vec vectors with TF-IDF with vectors normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_idf_avrg(contexts, words, vectors, textNum):\n",
    "    newVectors = []\n",
    "    for i in range(len(words)):\n",
    "        word = words[i]\n",
    "        vec = vectors[i]\n",
    "        tfIdfScore = tfidf(word, contexts[textNum], contexts)\n",
    "        newVectors.append(tfIdfScore*vec)\n",
    "    res = np.average(newVectors, axis=0)\n",
    "    if(np.linalg.norm(res) > 0):\n",
    "        res = res/np.linalg.norm(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_vector_tfidf(contexts, data, wordVec):\n",
    "    textVec= []\n",
    "    first = int(data['context_id'].tolist()[0]) - 1\n",
    "    for i in range(data.shape[0]):\n",
    "        #print(\"Text\", i, \"is OK\")\n",
    "        words = contexts[i].split()\n",
    "        vectors = []\n",
    "        validWords = []\n",
    "        for word in words:\n",
    "            if word in wordVec:\n",
    "                vectors.append(wordVec[word])\n",
    "                validWords.append(word)\n",
    "        textVec.append(tf_idf_avrg(contexts, validWords, vectors, i)) \n",
    "    return textVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_precesion_tfidf(num, dataGroups, wordVec):\n",
    "    contexts = set_contexts(num)\n",
    "    textVec = text_vector_tfidf(contexts, dataGroups[num], wordVec)\n",
    "    km = KMeans(n_clusters=2)\n",
    "    pred_sense = km.fit_predict(textVec)\n",
    "    gold_sense = dataGroups[num]['gold_sense_id'].values\n",
    "    res = adjusted_rand_score(pred_sense, gold_sense)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7939421411639748\n"
     ]
    }
   ],
   "source": [
    "res1 = predict_precesion_tfidf(0, dataGroups, wordVec)\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9279187206925574\n"
     ]
    }
   ],
   "source": [
    "res2 = predict_precesion_tfidf(1, dataGroups, wordVec)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33798134638470767\n"
     ]
    }
   ],
   "source": [
    "res3 = predict_precesion_tfidf(2, dataGroups, wordVec)\n",
    "print(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "res4 = predict_precesion_tfidf(3, dataGroups, wordVec)\n",
    "print(res4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Среднее значение ARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76496055206031\n"
     ]
    }
   ],
   "source": [
    "print((res1+res2+res3+res4)/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отчёт:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я также пробовал обучать tf-idf на всем корпусе текстов из train.csv, а не отдельно для каждого из главных слов, но это давало очень маленькие значения метрики ARI (среднее значение было отрицательным). Также пробовал использовать не tf-idf, а idf, в этом случае значение метрики ARI было 0.637 (0.28, 0.93, 0.34, 1), что почти тоже самое, что и при использовании Average of Word2Vec vectors (можно легко проверить, поменяв, в функции tf_idf_avrg \"tfIdfScore = tfidf(word, contexts[textNum], contexts)\" на \"tfIdfScore = idf(word, contexts)\") . Использование же tf давало среднее значение 0.31 (0.02, -0.01, 0.23, 1). Таким образом, луший результат дает классификация с помощью tf-idf и нормализации эмбеддингов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
